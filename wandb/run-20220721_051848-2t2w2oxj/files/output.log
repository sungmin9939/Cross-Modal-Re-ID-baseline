
==> Loading data..
Dataset sysu statistics:
  ------------------------------
  subset   | # ids | # images
  ------------------------------
  visible  |   395 |    22258
  thermal  |   395 |    11909
  ------------------------------
  query    |    96 |     3803
  gallery  |    96 |      301
  ------------------------------
Data Loading Time:	 17.564
==> Building model..
==> Start Training...
==> Preparing Data Loader...
0
[20927 20945 20945 ...  4515  4467  4490]
[10597 10605 10597 ...  1932  1948  1928]
Epoch: [0][0/347] lr:0.00010 Loss: 27.1782 (27.1782) rgb_proxy_loss: 13.3523 (13.3523) ir_proxy_loss: 13.8259 (13.8259) uni_proxy_loss: 0.0000 (0.0000
/data/Cross-Modal-Re-ID-baseline/loss.py:113: UserWarning: This overload of nonzero is deprecated:
	nonzero(Tensor input, *, Tensor out)
Consider using one of the following signatures instead:
	nonzero(Tensor input, *, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1595629403081/work/torch/csrc/utils/python_arg_parser.cpp:766.)
  with_pos_proxies = torch.nonzero(P_one_hot.sum(dim = 0) != 0).squeeze(dim = 1)   # The set of positive proxies of data in the batch
Epoch: [0][50/347] lr:0.00010 Loss: 27.0000 (26.5466) rgb_proxy_loss: 13.4876 (13.2725) ir_proxy_loss: 13.5124 (13.2741) uni_proxy_loss: 0.0000 (0.0000
Epoch: [0][100/347] lr:0.00010 Loss: 26.7775 (26.7326) rgb_proxy_loss: 13.3990 (13.3616) ir_proxy_loss: 13.3785 (13.3710) uni_proxy_loss: 0.0000 (0.0000
Epoch: [0][150/347] lr:0.00010 Loss: 26.8811 (26.8402) rgb_proxy_loss: 13.4338 (13.4146) ir_proxy_loss: 13.4474 (13.4256) uni_proxy_loss: 0.0000 (0.0000
Epoch: [0][200/347] lr:0.00010 Loss: 26.8213 (26.8601) rgb_proxy_loss: 13.4735 (13.4323) ir_proxy_loss: 13.3478 (13.4278) uni_proxy_loss: 0.0000 (0.0000
Epoch: [0][250/347] lr:0.00010 Loss: 26.2086 (26.8598) rgb_proxy_loss: 12.8885 (13.4326) ir_proxy_loss: 13.3201 (13.4272) uni_proxy_loss: 0.0000 (0.0000
Epoch: [0][300/347] lr:0.00010 Loss: 26.7326 (26.8434) rgb_proxy_loss: 13.2869 (13.4192) ir_proxy_loss: 13.4457 (13.4241) uni_proxy_loss: 0.0000 (0.0000
==> Preparing Data Loader...
1
[22141 22148 22154 ... 21298 21292 21296]
[11801 11797 11805 ... 10959 10962 10960]
Epoch: [1][0/347] lr:0.00010 Loss: 27.3925 (27.3925) rgb_proxy_loss: 13.4035 (13.4035) ir_proxy_loss: 13.9890 (13.9890) uni_proxy_loss: 0.0000 (0.0000
Epoch: [1][50/347] lr:0.00010 Loss: 26.6051 (26.5535) rgb_proxy_loss: 13.2709 (13.2645) ir_proxy_loss: 13.3342 (13.2889) uni_proxy_loss: 0.0000 (0.0000
Epoch: [1][100/347] lr:0.00010 Loss: 26.4011 (26.5093) rgb_proxy_loss: 13.3396 (13.2529) ir_proxy_loss: 13.0615 (13.2564) uni_proxy_loss: 0.0000 (0.0000
Epoch: [1][150/347] lr:0.00010 Loss: 27.4100 (26.4935) rgb_proxy_loss: 13.7591 (13.2491) ir_proxy_loss: 13.6510 (13.2444) uni_proxy_loss: 0.0000 (0.0000
Epoch: [1][200/347] lr:0.00010 Loss: 27.3088 (26.4479) rgb_proxy_loss: 13.8578 (13.2218) ir_proxy_loss: 13.4511 (13.2262) uni_proxy_loss: 0.0000 (0.0000
Epoch: [1][250/347] lr:0.00010 Loss: 26.6309 (26.4346) rgb_proxy_loss: 13.2228 (13.2139) ir_proxy_loss: 13.4080 (13.2207) uni_proxy_loss: 0.0000 (0.0000
Epoch: [1][300/347] lr:0.00010 Loss: 25.7693 (26.4000) rgb_proxy_loss: 13.2753 (13.2054) ir_proxy_loss: 12.4940 (13.1946) uni_proxy_loss: 0.0000 (0.0000
Test Epoch: 1
Extracting Gallery Feature...
Extracting Time:	 4.242
Extracting Query Feature...
Extracting Time:	 11.324
Evaluation Time:	 6.053
[0.01393637 0.02708388 0.03944255 0.05074941 0.06258217 0.07494084
 0.08440705 0.09334736 0.10544307 0.11780173 0.132264   0.14409676
 0.15750723 0.1667105  0.17985801 0.19195372 0.20378648 0.2148304
 0.22718906 0.23744412]
POOL:   Rank-1: 1.39% | Rank-5: 6.26% | Rank-10: 11.78%| Rank-20: 23.74%| mAP: 3.32%| mINP: 1.75%
FC:   Rank-1: 1.24% | Rank-5: 6.76% | Rank-10: 12.81%| Rank-20: 23.43%| mAP: 3.41%| mINP: 1.89%
Best Epoch [1]
==> Preparing Data Loader...
2
[14673 14693 14726 ... 20987 20993 20997]
[ 6356  6351  6352 ... 10654 10663 10662]
Epoch: [2][0/347] lr:0.00010 Loss: 26.2069 (26.2069) rgb_proxy_loss: 13.1631 (13.1631) ir_proxy_loss: 13.0438 (13.0438) uni_proxy_loss: 0.0000 (0.0000
Epoch: [2][50/347] lr:0.00010 Loss: 26.1956 (26.1100) rgb_proxy_loss: 13.1672 (13.0543) ir_proxy_loss: 13.0284 (13.0557) uni_proxy_loss: 0.0000 (0.0000
Epoch: [2][100/347] lr:0.00010 Loss: 26.0943 (26.1079) rgb_proxy_loss: 13.0811 (13.0616) ir_proxy_loss: 13.0132 (13.0463) uni_proxy_loss: 0.0000 (0.0000
Epoch: [2][150/347] lr:0.00010 Loss: 25.8297 (26.1028) rgb_proxy_loss: 12.7550 (13.0626) ir_proxy_loss: 13.0747 (13.0402) uni_proxy_loss: 0.0000 (0.0000
Epoch: [2][200/347] lr:0.00010 Loss: 25.7936 (26.0821) rgb_proxy_loss: 12.7725 (13.0562) ir_proxy_loss: 13.0210 (13.0259) uni_proxy_loss: 0.0000 (0.0000
Epoch: [2][250/347] lr:0.00010 Loss: 26.3640 (26.0738) rgb_proxy_loss: 13.2069 (13.0441) ir_proxy_loss: 13.1572 (13.0297) uni_proxy_loss: 0.0000 (0.0000
Epoch: [2][300/347] lr:0.00010 Loss: 25.6622 (26.0387) rgb_proxy_loss: 12.9398 (13.0306) ir_proxy_loss: 12.7225 (13.0081) uni_proxy_loss: 0.0000 (0.0000
==> Preparing Data Loader...
3
[21512 21504 21520 ...  7484  7438  7460]
[11158 11157 11166 ...  3233  3213  3239]
Epoch: [3][0/347] lr:0.00010 Loss: 25.7429 (25.7429) rgb_proxy_loss: 12.7801 (12.7801) ir_proxy_loss: 12.9628 (12.9628) uni_proxy_loss: 0.0000 (0.0000
Epoch: [3][50/347] lr:0.00010 Loss: 25.1181 (25.9038) rgb_proxy_loss: 12.5609 (12.9612) ir_proxy_loss: 12.5573 (12.9425) uni_proxy_loss: 0.0000 (0.0000
Epoch: [3][100/347] lr:0.00010 Loss: 25.3567 (25.9070) rgb_proxy_loss: 12.6312 (12.9492) ir_proxy_loss: 12.7255 (12.9579) uni_proxy_loss: 0.0000 (0.0000
Epoch: [3][150/347] lr:0.00010 Loss: 25.7379 (25.8630) rgb_proxy_loss: 12.5763 (12.9390) ir_proxy_loss: 13.1616 (12.9239) uni_proxy_loss: 0.0000 (0.0000
Epoch: [3][200/347] lr:0.00010 Loss: 25.3800 (25.8489) rgb_proxy_loss: 12.6013 (12.9367) ir_proxy_loss: 12.7788 (12.9121) uni_proxy_loss: 0.0000 (0.0000
Epoch: [3][250/347] lr:0.00010 Loss: 26.0653 (25.8382) rgb_proxy_loss: 13.0470 (12.9367) ir_proxy_loss: 13.0183 (12.9015) uni_proxy_loss: 0.0000 (0.0000
Epoch: [3][300/347] lr:0.00010 Loss: 25.3353 (25.8249) rgb_proxy_loss: 12.5870 (12.9283) ir_proxy_loss: 12.7483 (12.8967) uni_proxy_loss: 0.0000 (0.0000
Test Epoch: 3
Extracting Gallery Feature...
Extracting Time:	 1.651
Extracting Query Feature...
Extracting Time:	 9.833
Evaluation Time:	 5.986
[0.01367342 0.02524323 0.03865369 0.05232711 0.06284513 0.07388903
 0.08388115 0.09518801 0.10807257 0.11964238 0.1301604  0.14225611
 0.15251118 0.16460688 0.1777544  0.19142783 0.20247173 0.2122009
 0.22087826 0.23349987]
POOL:   Rank-1: 1.37% | Rank-5: 6.28% | Rank-10: 11.96%| Rank-20: 23.35%| mAP: 3.25%| mINP: 1.74%
FC:   Rank-1: 1.37% | Rank-5: 6.42% | Rank-10: 12.04%| Rank-20: 23.64%| mAP: 3.38%| mINP: 1.86%
Best Epoch [3]
==> Preparing Data Loader...
4
[ 9434  9521  9473 ... 21081 21071 21074]
[ 4073  4085  4070 ... 10737 10731 10742]
Epoch: [4][0/347] lr:0.00010 Loss: 26.5213 (26.5213) rgb_proxy_loss: 13.2908 (13.2908) ir_proxy_loss: 13.2305 (13.2305) uni_proxy_loss: 0.0000 (0.0000
Epoch: [4][50/347] lr:0.00010 Loss: 25.8333 (25.7882) rgb_proxy_loss: 12.9725 (12.8772) ir_proxy_loss: 12.8608 (12.9110) uni_proxy_loss: 0.0000 (0.0000
Epoch: [4][100/347] lr:0.00010 Loss: 25.6358 (25.7398) rgb_proxy_loss: 12.9774 (12.8689) ir_proxy_loss: 12.6584 (12.8709) uni_proxy_loss: 0.0000 (0.0000
Epoch: [4][150/347] lr:0.00010 Loss: 25.3686 (25.7265) rgb_proxy_loss: 12.5922 (12.8821) ir_proxy_loss: 12.7764 (12.8444) uni_proxy_loss: 0.0000 (0.0000
Epoch: [4][200/347] lr:0.00010 Loss: 25.7420 (25.7214) rgb_proxy_loss: 12.8258 (12.8880) ir_proxy_loss: 12.9162 (12.8334) uni_proxy_loss: 0.0000 (0.0000
Epoch: [4][250/347] lr:0.00010 Loss: 25.5666 (25.7107) rgb_proxy_loss: 12.8041 (12.8844) ir_proxy_loss: 12.7625 (12.8263) uni_proxy_loss: 0.0000 (0.0000
Epoch: [4][300/347] lr:0.00010 Loss: 25.6658 (25.7049) rgb_proxy_loss: 12.8669 (12.8788) ir_proxy_loss: 12.7990 (12.8261) uni_proxy_loss: 0.0000 (0.0000
==> Preparing Data Loader...
5
[ 6917  6921  6953 ... 21217 21216 21219]
[ 3007  3005  3007 ... 10872 10872 10879]
Epoch: [5][0/347] lr:0.00010 Loss: nan (nan) rgb_proxy_loss: 12.5984 (12.5984) ir_proxy_loss: 12.6902 (12.6902) uni_proxy_loss: nan (nan
Epoch: [5][50/347] lr:0.00010 Loss: nan (nan) rgb_proxy_loss: 13.4373 (12.9151) ir_proxy_loss: 13.9680 (12.9809) uni_proxy_loss: nan (nan
Epoch: [5][100/347] lr:0.00010 Loss: nan (nan) rgb_proxy_loss: 13.2441 (12.8934) ir_proxy_loss: 13.1229 (12.9634) uni_proxy_loss: nan (nan
Epoch: [5][150/347] lr:0.00010 Loss: nan (nan) rgb_proxy_loss: 13.1382 (12.8859) ir_proxy_loss: 13.0760 (12.9364) uni_proxy_loss: nan (nan
Epoch: [5][200/347] lr:0.00010 Loss: nan (nan) rgb_proxy_loss: 12.8554 (12.8485) ir_proxy_loss: 13.0030 (12.9094) uni_proxy_loss: nan (nan
Epoch: [5][250/347] lr:0.00010 Loss: nan (nan) rgb_proxy_loss: 12.2491 (12.7908) ir_proxy_loss: 12.9311 (12.8807) uni_proxy_loss: nan (nan
Traceback (most recent call last):
  File "train.py", line 538, in <module>
    train(epoch)
  File "train.py", line 401, in train
    optimizer.step()
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/lr_scheduler.py", line 67, in wrapper
    return wrapped(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 15, in decorate_context
    return func(*args, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/optim/adam.py", line 99, in step
    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)
KeyboardInterrupt